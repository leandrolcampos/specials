{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright 2024 The Specials Authors. Licensed under the Apache License, Version 2.0 (the \"License\").*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Some of the code in this file is adapted from:_\n",
    "\n",
    "_modularml/mojo_<br>\n",
    "_Copyright (c) 2023, Modular Inc._<br>\n",
    "_Licensed under the Apache License v2.0 with LLVM Exceptions._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">This notebook requires Mojo <code>v0.7.0</code>. Make sure you have the correct Mojo version installed before running it.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `expm1` function in Specials\n",
    "\n",
    "In this notebook, we compare the implementation of the `expm1` function in Specials with the implementations from the Mojo standard library and NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `expm1` function computes $e^x - 1$ in a numerically stable way. It is semantically equivalent to `exp(x) - 1`, but it is more accurate for `x` close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to implement this function in Specials not because there is any issue with the corresponding function in the Mojo standard library, but rather because we are studying how to implement table-based numerical methods following the paper:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tang, P. T. P. (1992). Table-driven implementation of the expm1 function in IEEE floating-point arithmetic. _ACM Transactions on Mathematical Software (TOMS)_, 18(2), 211-222. [[Link](https://doi.org/10.1145/146847.146928)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of maximum relative error, our experiments show that the implementation in Specials is as accurate as the evaluated alternatives. Regarding the average relative error, the implementation in Specials can be at least 12.9 times more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mean execution time, the results indicated that the implementation in Specials is about 1.07 to 3.1 times faster than the Mojo standard library implementation and about 2.7 to 13.7 times faster than the NumPy implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before delving into the experiments, letâ€™s explore how we can use the implementation in Specials through a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp(0) = 1.0\n",
      "exp(0) - 1.0 = 0.0\n"
     ]
    }
   ],
   "source": [
    "import specials\n",
    "\n",
    "let exp_0 = specials.exp(Float64(0))\n",
    "print(\"exp(0) =\", exp_0)\n",
    "\n",
    "let exp_0_minus_1 = specials.expm1(Float64(0))\n",
    "print(\"exp(0) - 1.0 =\", exp_0_minus_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experimental settings\n",
    "\n",
    "In this section, we outline the experimental settings. From the definition of domains and precision considerations to the metrics used for accuracy and computational performance evaluation, these settings lay the foundation for an objective assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We uniformly sample 250,000 values for `expm1` argument from 5 intervals of the form $[a_i, b_i]$, referred to as _domains_, where $a_i$ and $b_i$ are the minimum and maximum values of each domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the experiments, we work with single- and double-precision floating-point values (`float32` and `float64`, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the accuracy of the function implementations, we use the _relative error_. Let $\\hat{x}$ be an approximation of the real number $x$. The relative error $E_{\\text{rel}}(\\hat{x})$ is given by:\n",
    "\n",
    "$$E_{\\text{rel}}(\\hat{x}) = \\frac{|x - \\hat{x}|}{|x|}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the argument, the exact but unknown value of each function, represented in the formula above by the real number $x$, is computed with high precision using the Python library [`mpmath`](https://mpmath.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare different implementations in terms of accuracy, we calculate the maximum and mean values of the relative error for each combination of implementation and domain. Lower values indicate higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quantifying computational performance, we measure the _execution time_: in Mojo, using the `benchmark` module, and in Python, by defining a function based on the `timeit` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare different implementations in terms of computational performance, we calculate the mean execution time for each combination of implementation and domain. Smaller results indicate better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we introduce the auxiliary functions essential for conducting our experiments and measuring results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "from importlib.util import find_spec\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "fix = \"\"\"\n",
    "-------------------------------------------------------------------------\n",
    "To fix this, follow the steps in the link below:\n",
    "    https://github.com/modularml/mojo/issues/1085#issuecomment-1771403719\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def install_if_missing(name: str):\n",
    "    if find_spec(name.replace(\"-\", \"_\")):\n",
    "        return\n",
    "\n",
    "    print(f\"The package `{name}` was not found. We will install it...\")\n",
    "    try:\n",
    "        if shutil.which(\"python3\"): python = \"python3\"\n",
    "        elif shutil.which(\"python\"): python = \"python\"\n",
    "        else:\n",
    "            raise RuntimeError(\"Python is not on `PATH`. \" + fix)\n",
    "        subprocess.check_call([python, \"-m\", \"pip\", \"install\", name])\n",
    "    except:\n",
    "        raise ImportError(f\"The package `{name}` was not found. \" + fix)\n",
    "\n",
    "install_if_missing(\"mpmath\")\n",
    "install_if_missing(\"numpy\")\n",
    "install_if_missing(\"tabulate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import mpmath as mp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def py_numpy_expm1(x):\n",
    "    \"\"\"Computes `exp(x) - 1` for all elements in the given array using NumPy.\"\"\"\n",
    "    return np.expm1(x)\n",
    "\n",
    "\n",
    "def py_mpmath_expm1(x):\n",
    "    \"\"\"Computes `exp(x) - 1` for all elements in the given array using mpmath.\"\"\"\n",
    "    def _mp_expm1_impl(a):\n",
    "        with mp.workdps(350):\n",
    "            res = mp.expm1(mp.mpf(a))\n",
    "        return res\n",
    "\n",
    "    dtype = np.result_type(x)\n",
    "    return np.frompyfunc(_mp_expm1_impl, 1, 1)(x).astype(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from python import Python\n",
    "from python.object import PythonObject\n",
    "\n",
    "from specials._internal.tensor import (\n",
    "    elementwise,\n",
    "    random_uniform,\n",
    "    run_benchmark,\n",
    "    tensor_to_numpy_array,\n",
    "    UnaryOperator,\n",
    ")\n",
    "\n",
    "Python.add_to_path(\".\")\n",
    "\n",
    "\n",
    "fn solution_report[\n",
    "    solution_name: StringLiteral,\n",
    "    func: UnaryOperator,\n",
    "    dtype: DType,\n",
    "    simd_width: Int = simdwidthof[dtype](),\n",
    "](x: Tensor[dtype], truth: PythonObject) raises -> PythonObject:\n",
    "    \"\"\"Computes the evaluation metrics for a given numerical solution in Mojo.\"\"\"\n",
    "    let builtins = Python.import_module(\"builtins\")\n",
    "    let np = Python.import_module(\"numpy\")\n",
    "    let numerics_testing = Python.import_module(\"specials._internal.numerics_testing\")\n",
    "\n",
    "    let result = elementwise[func](x)\n",
    "    let msecs = run_benchmark[func](x).mean(\"ms\")\n",
    "    let relerr = numerics_testing.py_relative_error(\n",
    "        tensor_to_numpy_array(result), truth\n",
    "    )\n",
    "\n",
    "    let report = builtins.list()\n",
    "    _ = report.append(solution_name)\n",
    "    _ = report.append(np.max(relerr))\n",
    "    _ = report.append(np.mean(relerr))\n",
    "    _ = report.append(msecs)\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "from timeit import timeit\n",
    "\n",
    "from specials._internal import numerics_testing\n",
    "\n",
    "\n",
    "def py_benchmark(func, *args):\n",
    "    \"\"\"Computes the average execution time of a Python function.\"\"\"\n",
    "    # Warmup phase\n",
    "    _ = timeit(lambda: func(*args), number=2)\n",
    "\n",
    "    msecs = 1000 * timeit(lambda: func(*args), number=100) / 100\n",
    "    return msecs\n",
    "\n",
    "\n",
    "def py_solution_report(solution_name, func, x_arr, truth):\n",
    "    \"\"\"Computes the evaluation metrics for a given numerical solution in Python.\"\"\"\n",
    "    result = func(x_arr)\n",
    "    msecs = py_benchmark(func, x_arr)\n",
    "    relerr = numerics_testing.py_relative_error(result, truth)\n",
    "\n",
    "    return [solution_name, np.max(relerr), np.mean(relerr), msecs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "from tabulate import tabulate, SEPARATING_LINE\n",
    "\n",
    "\n",
    "def py_format_domain_name(domain_name):\n",
    "    \"\"\"Formats the domain name for printing.\"\"\"\n",
    "    values = [float(n) for n in domain_name.split(\",\")]\n",
    "    formatted = []\n",
    "\n",
    "    for value in values:\n",
    "        if value == int(value):\n",
    "            if np.abs(value) > 10e3:\n",
    "                formatted.append(f\"{int(value):.0e}\")\n",
    "            else:\n",
    "                formatted.append(f\"{int(value)}\")\n",
    "        else:\n",
    "            if np.abs(value) < 0.001:\n",
    "                formatted.append(f\"{value:.0e}\")\n",
    "            elif np.log10(np.abs(value)) >= 3:\n",
    "                formatted.append(f\"{value:.1e}\")\n",
    "            else:\n",
    "                formatted.append(f\"{value:.1f}\")\n",
    "\n",
    "    return f\"{formatted[0]},{formatted[1]}\"\n",
    "\n",
    "\n",
    "def py_print_table(\n",
    "    data, domain_names, num_solutions, experiment_name\n",
    "):\n",
    "    \"\"\"Prints the evaluation metrics for all numerical solutions.\"\"\"\n",
    "    headers = [\n",
    "        \"\\nDomain\",\n",
    "        \"\\nSolution\",\n",
    "        \"Maximum\\nRelative Error\",\n",
    "        \"Mean\\nRelative Error\",\n",
    "        \"Mean Execution Time\\n(in milliseconds)\",\n",
    "    ]\n",
    "\n",
    "    # Insert domain names\n",
    "    current_domain = 0\n",
    "    for i, report in enumerate(data):\n",
    "        if i % num_solutions == 0:\n",
    "            domain_name = py_format_domain_name(domain_names[current_domain])\n",
    "            data[i].insert(0, domain_name)\n",
    "            current_domain += 1\n",
    "        else:\n",
    "            data[i].insert(0, \"\")\n",
    "\n",
    "    # Insert horizontal lines between domains\n",
    "    for index in range(num_solutions, len(data) + num_solutions, num_solutions + 1):\n",
    "        data.insert(index, SEPARATING_LINE)\n",
    "\n",
    "    print(f\"\\nExperiment: {experiment_name}\\n\")\n",
    "\n",
    "    floatfmt = (\".2e\", \".2e\", \".2e\", \".2e\", \".3f\")\n",
    "    table = tabulate(data, headers, tablefmt=\"simple\", floatfmt=floatfmt)\n",
    "\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from utils.static_tuple import StaticTuple\n",
    "\n",
    "\n",
    "fn run_experiment[\n",
    "    dtype: DType,\n",
    "    num_domains: Int,\n",
    "](\n",
    "    name: StringLiteral,\n",
    "    min_values: StaticTuple[num_domains, FloatLiteral],\n",
    "    max_values: StaticTuple[num_domains, FloatLiteral],\n",
    "    num_samples: Int,\n",
    "    truth_func: PythonObject,\n",
    "    numpy_func: PythonObject,\n",
    "    report_func: PythonObject,\n",
    "    print_func: PythonObject,\n",
    ") raises:\n",
    "    \"\"\"Runs the experiment.\"\"\"\n",
    "    let builtins = Python.import_module(\"builtins\")\n",
    "\n",
    "    random.seed(42)\n",
    "\n",
    "    let domain_names = builtins.list()\n",
    "    let data = builtins.list()\n",
    "\n",
    "    print(\"Running the experiment. This may take a while...\\n\")\n",
    "\n",
    "    for i in range(len(max_values)):\n",
    "        let min_value = min_values[i]\n",
    "        let max_value = max_values[i]\n",
    "\n",
    "        _ = domain_names.append(String(\"\") + str(min_value) + \",\" + str(max_value))\n",
    "\n",
    "        let a = random_uniform[dtype](min_value, max_value, num_samples)\n",
    "        let a_arr = tensor_to_numpy_array(a)\n",
    "\n",
    "        # mpmath\n",
    "        let truth = truth_func(a_arr)\n",
    "\n",
    "        # Specials\n",
    "        let specials_report = solution_report[\"Specials\", specials.expm1, dtype](\n",
    "            a, truth\n",
    "        )\n",
    "        _ = data.append(specials_report)\n",
    "\n",
    "        # Mojo\n",
    "        let mojo_report = solution_report[\"Mojo\", math.expm1, dtype](a, truth)\n",
    "        _ = data.append(mojo_report)\n",
    "\n",
    "        # NumPy\n",
    "        let numpy_report = report_func(\"NumPy\", numpy_func, a_arr, truth)\n",
    "        _ = data.append(numpy_report)\n",
    "\n",
    "    _ = print_func(data, domain_names, 3, String(name) + \" (\" + str(dtype) + \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment results\n",
    "\n",
    "In this section, we delve into the results of our experiments, comparing the implementation of `expm1` in Specials with its counterparts in Mojo standard library and NumPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the findings across two precision settings: `float32` and `float64`. Each experiment explores accuracy and computational performance across distinct domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the experiment. This may take a while...\n",
      "\n",
      "\n",
      "Experiment: Expm1 Function (float32)\n",
      "\n",
      "                                   Maximum              Mean    Mean Execution Time\n",
      "Domain        Solution      Relative Error    Relative Error      (in milliseconds)\n",
      "------------  ----------  ----------------  ----------------  ---------------------\n",
      "-1e-05,1e-05  Specials            0.00e+00          0.00e+00                  0.089\n",
      "              Mojo                7.15e-08          2.86e-13                  0.223\n",
      "              NumPy               7.15e-08          2.86e-13                  0.693\n",
      "------------  ----------  ----------------  ----------------  ---------------------\n",
      "-1,1          Specials            1.19e-07          5.76e-10                  0.200\n",
      "              Mojo                1.19e-07          7.66e-09                  0.433\n",
      "              NumPy               1.19e-07          7.66e-09                  1.810\n",
      "------------  ----------  ----------------  ----------------  ---------------------\n",
      "-10,10        Specials            1.19e-07          1.95e-10                  0.181\n",
      "              Mojo                1.19e-07          5.62e-09                  0.518\n",
      "              NumPy               1.19e-07          5.62e-09                  2.068\n",
      "------------  ----------  ----------------  ----------------  ---------------------\n",
      "-30,30        Specials            1.19e-07          1.53e-10                  0.173\n",
      "              Mojo                1.19e-07          4.61e-09                  0.538\n",
      "              NumPy               1.19e-07          4.61e-09                  2.374\n",
      "------------  ----------  ----------------  ----------------  ---------------------\n",
      "-85,85        Specials            1.19e-07          1.59e-10                  0.184\n",
      "              Mojo                1.19e-07          4.28e-09                  0.465\n",
      "              NumPy               1.19e-07          4.28e-09                  2.079\n"
     ]
    }
   ],
   "source": [
    "let sml_f32 = 1e-7\n",
    "\n",
    "run_experiment[DType.float32, num_domains=5](\n",
    "    name=\"Expm1 Function\",\n",
    "    min_values=StaticTuple[5, FloatLiteral](-100 * sml_f32, -1.0, -10, -30.0, -85.0),\n",
    "    max_values=StaticTuple[5, FloatLiteral](100 * sml_f32, 1.0, 10.0, 30.0, 85.0),\n",
    "    num_samples=250_000,\n",
    "    truth_func=py_mpmath_expm1,\n",
    "    numpy_func=py_numpy_expm1,\n",
    "    report_func=py_solution_report,\n",
    "    print_func=py_print_table,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the experiment. This may take a while...\n",
      "\n",
      "\n",
      "Experiment: Expm1 Function (float64)\n",
      "\n",
      "                                   Maximum              Mean    Mean Execution Time\n",
      "Domain        Solution      Relative Error    Relative Error      (in milliseconds)\n",
      "------------  ----------  ----------------  ----------------  ---------------------\n",
      "-2e-14,2e-14  Specials            0.00e+00          0.00e+00                  0.243\n",
      "              Mojo                0.00e+00          0.00e+00                  0.261\n",
      "              NumPy               0.00e+00          0.00e+00                  0.659\n",
      "------------  ----------  ----------------  ----------------  ---------------------\n",
      "-1,1          Specials            2.22e-16          1.11e-18                  0.487\n",
      "              Mojo                2.22e-16          1.44e-17                  0.527\n",
      "              NumPy               2.22e-16          1.44e-17                  1.955\n",
      "------------  ----------  ----------------  ----------------  ---------------------\n",
      "-10,10        Specials            2.22e-16          3.54e-19                  0.454\n",
      "              Mojo                2.22e-16          1.04e-17                  0.673\n",
      "              NumPy               2.22e-16          1.04e-17                  2.210\n",
      "------------  ----------  ----------------  ----------------  ---------------------\n",
      "-30,30        Specials            2.20e-16          2.52e-19                  0.457\n",
      "              Mojo                2.22e-16          8.51e-18                  0.655\n",
      "              NumPy               2.22e-16          8.51e-18                  2.428\n",
      "------------  ----------  ----------------  ----------------  ---------------------\n",
      "-85,85        Specials            2.22e-16          2.58e-19                  0.444\n",
      "              Mojo                2.22e-16          7.99e-18                  0.687\n",
      "              NumPy               2.22e-16          7.99e-18                  2.493\n"
     ]
    }
   ],
   "source": [
    "let sml_f64 = 2e-16\n",
    "\n",
    "run_experiment[DType.float64, num_domains=5](\n",
    "    name=\"Expm1 Function\",\n",
    "    min_values=StaticTuple[5, FloatLiteral](-100 * sml_f64, -1.0, -10, -30.0, -85.0),\n",
    "    max_values=StaticTuple[5, FloatLiteral](100 * sml_f64, 1.0, 10.0, 30.0, 85.0),\n",
    "    num_samples=250_000,\n",
    "    truth_func=py_mpmath_expm1,\n",
    "    numpy_func=py_numpy_expm1,\n",
    "    report_func=py_solution_report,\n",
    "    print_func=py_print_table,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In terms of maximum relative error, our experiments showed that the implementation in Specials is as accurate as the evaluated alternatives.\n",
    "\n",
    "- Regarding the average relative error, the implementation in Specials can be at least 12.9 times more accurate.\n",
    "\n",
    "- For mean execution time, the results indicated that the implementation in Specials is about 1.07 to 3.1 times faster than the Mojo standard library implementation and about 2.7 to 13.7 times faster than the NumPy implementation.\n",
    "\n",
    "- The results underscore Specials' ability to provide superior accuracy without compromising computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A: System information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, information about the system used to run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modular 0.4.1 (2d8afe15)\n",
      "mojo 0.7.0 (af002202)\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "\n",
    "subprocess.run([\"modular\", \"-v\"])\n",
    "subprocess.run([\"mojo\", \"-v\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Information\n",
      "    OS          : linux\n",
      "    CPU         : alderlake\n",
      "    Arch        : x86_64-unknown-linux-gnu\n",
      "    Num Cores   : 8\n",
      "    CPU Features: sse4 avx avx2 avx_vnni\n"
     ]
    }
   ],
   "source": [
    "from sys.info import (\n",
    "    os_is_linux,\n",
    "    os_is_windows,\n",
    "    os_is_macos,\n",
    "    has_sse4,\n",
    "    has_avx,\n",
    "    has_avx2,\n",
    "    has_avx512f,\n",
    "    has_vnni,\n",
    "    has_neon,\n",
    "    is_apple_m1,\n",
    "    has_intel_amx,\n",
    "    num_physical_cores,\n",
    "    _current_target,\n",
    "    _current_cpu,\n",
    "    _triple_attr,\n",
    ")\n",
    "\n",
    "let os: StringLiteral\n",
    "if os_is_linux():\n",
    "    os = \"linux\"\n",
    "elif os_is_macos():\n",
    "    os = \"macOS\"\n",
    "else:\n",
    "    os = \"windows\"\n",
    "\n",
    "let cpu = String(_current_cpu())\n",
    "let arch = String(_triple_attr())\n",
    "\n",
    "var cpu_features = String(\"\")\n",
    "if has_sse4():\n",
    "    cpu_features += \" sse4\"\n",
    "if has_avx():\n",
    "    cpu_features += \" avx\"\n",
    "if has_avx2():\n",
    "    cpu_features += \" avx2\"\n",
    "if has_avx512f():\n",
    "    cpu_features += \" avx512f\"\n",
    "if has_vnni():\n",
    "    if has_avx512f():\n",
    "        cpu_features += \" avx512_vnni\"\n",
    "    else:\n",
    "        cpu_features += \" avx_vnni\"\n",
    "if has_intel_amx():\n",
    "    cpu_features += \" intel_amx\"\n",
    "if has_neon():\n",
    "    cpu_features += \" neon\"\n",
    "if is_apple_m1():\n",
    "    cpu_features += \" apple_m1\"\n",
    "\n",
    "if len(cpu_features) > 0:\n",
    "    cpu_features = cpu_features[1:]\n",
    "\n",
    "print(\"System Information\")\n",
    "print(\"    OS          :\", os)\n",
    "print(\"    CPU         :\", cpu)\n",
    "print(\"    Arch        :\", arch)\n",
    "print(\"    Num Cores   :\", num_physical_cores())\n",
    "print(\"    CPU Features:\", cpu_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpmath version: 1.3.0\n",
      "NumPy version: 1.26.0\n",
      "Python version: 3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 15:07:28) [GCC 12.3.0]\n",
      "Tabulate version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "import pkg_resources\n",
    "import sys\n",
    "\n",
    "def get_version(package):\n",
    "    \"\"\"Returns the version of a Python package.\"\"\"\n",
    "    return pkg_resources.get_distribution(package).version\n",
    "\n",
    "print(\"mpmath version:\", mp.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Tabulate version:\", get_version(\"tabulate\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
